\section{Function Description}

This section provides an operational description of the software,
detailing user profiles and core functionalities.

\subsection{User Profiles}

The system is designed to support multiple user categories, each with
distinct interactions listed below.

\begin{itemize}
    \item
      \textbf{General Users:}
      Individuals who interact with the \naosix\ robot through voice
      commands. These users receive spoken responses generated by the AI
      model, enabling natural language conversations.

    \item
      \textbf{Developers \& Administrators:}
      Team members responsible for maintaining and updating the software
      infrastructure. They manage Docker containers, APIs, and server
      configurations to ensure smooth operation.

    \item
      \textbf{Instructors \& Researchers:}
      Users interested in testing AI-driven educational and interactive
      features. They may modify chatbot personalities, analyze
      interactions, or customize conversation topics.
\end{itemize}

\subsection{Core Functionalities}

Important to understanding the core functionality of the project is the
speech-response loop. In the successful case, the system detects sound
and begins recording input. Once silence is detected, it sends the
speech input for processing. After the speech is transcribed, an LLM
response is generated, and the LLM response is performed by the \naosix\
robot. The entire speech-response loop is illustrated in Fig.
\ref{fig:speech_response_loop} below.

\begin{figure}[h]
  \centering
  \includegraphics[width = 0.5\textwidth]{speech-response-loop}
  \caption{Speech-response loop diagram.}
  \label{fig:speech_response_loop}
\end{figure}

The system provides the following core functionalities:

\subsubsection{Voice Interaction with \naosix}

Users initiate communication currently with by running a python script,
activating the \naosix\ robot's listening mode. Eventually, users will
initiate by speaking a predefined keyphrase. The robot records the
user's voice input and transmits the data to the backend for processing.
The ALSoundDetection API determines when to start and stop recording,
ensuring efficient voice capture.

\subsubsection{Speech Recognition and Transcription}

To enhance the accuracy of voice recognition, a dedicated speech
recognition module is implemented within a Docker container. This module
utilizes Google's Speech-to-Text API to transcribe recorded audio,
superseding the \naosix{}'s inferior built-in capabilities. The
transcribed text is then forwarded to the AI processing unit.

\subsubsection{AI-Powered Response Generation}

Once the user's input is transcribed, it is sent to an AI language model
for processing. The system utilizes Large Language Models (LLMs) to
generate appropriate and contextually relevant responses. The generated
response is then transmitted back to the \naosix\ robot.

\subsubsection{Speech and Animation Output}

The \naosix\ robot delivers responses using both speech and animations.
The AI-generated text is converted into speech and played through the
robot's speakers, while predefined animations enhance engagement and
interactivity.

\subsubsection{Middleware API for Communication}

A middleware API, developed using Node.js and Express.js, facilitates
communication between the \naosix\ robot and backend services. This API
manages API calls, routes transcribed text to the LLM, and handles voice
recording file transfers.

\subsubsection{Web-Based Management Interface}

A planned web-based interface will provide administrators and
researchers with tools to manage chatbot personalities and control
\naosix{}'s functionalities. This interface will allow users to
configure conversation styles, select AI models, and oversee basic robot
operations.

\subsubsection{Future Enhancements}

Further improvements will include the ability to switch between
different LLMs, allowing for more customizable interactions.
Additionally, secure encrypted network communications will be
implemented to ensure safe data transmission between the \naosix\ robot
and backend servers.

