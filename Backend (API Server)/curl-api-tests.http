###
// Get the available models on the ollama server
curl -X GET \
  "http://localhost:45679/downloaded-models"

###
// Lists currently running models
curl -X GET \
  "http://localhost:45679/modelsrunning"

###
// Pull a model
curl -X PUT \
  -H "Content-type: application/json" \
  -H "Accept: application/json" \
  -d '{"model":"qwen2.5:0.5b"}' \
  "http://localhost:45679/download"


###
// Load a model
curl http://localhost:45679/api/chat -d '{
  "model": "qwen2.5:0.5b",
  "messages": []
}'

###
// Unload a model
curl http://localhost:45679/api/chat -d '{
  "model": "qwen2.5:0.5b",
  "messages": [],
  "keep_alive": 0
}'
###
// GET MODEL INFORMATION
curl -X GET \
  -H "Content-type: application/json" \
  -H "Accept: application/json" \
  -d '{"model":"qwen2.5:0.5b"}' \
  "http://localhost:45679/modelinfo"

###

curl -X DELETE \
  "model": "qwen2.5:0.5b"
 "http://localhost:45679/delete" -d '{
}'




###
// Chat with the bot (STREAMED)
// The json will be scattered due to it being "streamed"
curl http://localhost:45679/api/chat -d '{
  "model": "qwen2.5:0.5b",
  "messages": [
    {
      "role": "user",
      "content": "hi"
    }
  ]
}'

###
// Chat with the bot (NOT STREAMED)
// The json will be complete
curl http://localhost:45679/api/chat -d '{
  "model": "qwen2.5:0.5b",
  "messages": [
    {
      "role": "user",
      "content": "hi"
    }
  ],
  "stream": false
}'

###
// Chat with images (For long shot project)
curl http://localhost:45679/api/chat -d '{
  "model": "llava:7b",
  "messages": [
    {
      "role": "user",
      "content": "what is in this image?",
      "images": ["https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fwallpaperaccess.com%2Ffull%2F2111331.jpg&f=1&nofb=1&ipt=77b8d8ea6a751d20b0746afe0f7b9487d460c361ae1c1cd7d259385bde996d8b&ipo=images"]
    }
  ]
}'

